{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modules\n",
    "\n",
    "> This package contains the modules that make up the [FastSpeech](https://arxiv.org/abs/1905.09263) architecture\n",
    "![](../assets/fastspeech-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "import math\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from fastspeech.visualize import show_mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def get_shape(*args: tensor): return tuple(map(lambda x: x.shape, [*args]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "vocab_sz = 50\n",
    "n_hidden = 48\n",
    "filter_sz = 64\n",
    "n_heads = 2\n",
    "bs = 16\n",
    "seq_len = 18\n",
    "out_shape = [bs, seq_len, n_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "sample_batch = torch.randint(vocab_sz, (bs, seq_len))\n",
    "sample_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## phoneme embedding\n",
    "> The first module of the fastspeech architecture is the input embeddings where they embed the input phonemes in to the models hidden dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(vocab_sz, n_hidden)\n",
    "samples_embedded = embedding(sample_batch)\n",
    "samples_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(out_shape, samples_embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## positional embedding\n",
    "> After the embedding layer in the fastspeech model it inputs positional embedding to allow the model to have information on the positons of inputs. The positional embedding used in the [FastSpeech](https://arxiv.org/abs/1905.09263) paper is the function described in the [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_positional_embeddings(seq_len, # The length of the sequence\n",
    "                              d_model, # The hidden dimension of the model\n",
    "                              device: torch.device =None): # Device you want to use\n",
    "    pos = torch.arange(d_model, device=device)[None, :]\n",
    "    i = torch.arange(seq_len, device=device)[:, None]\n",
    "    angle = pos / torch.pow(10000, 2 * i / d_model)\n",
    "    pos_emb = torch.zeros(angle.shape, device=device)\n",
    "    pos_emb[0::2,:], pos_emb[1::2,:] = angle[0::2,:].sin(), angle[1::2,:].cos()\n",
    "    return pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb = get_positional_embeddings(seq_len, n_hidden)\n",
    "pos_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(pos_emb.shape, [seq_len, n_hidden])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = samples_embedded + pos_emb\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(inp.shape, out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feed-forward transformer\n",
    "> This component of the model is the engine of the model. It is what will be used to make up the phoneme encoder and mel spectrogram decoder. It consists of a Multi-Head Attention block and a Conv Network. An additional note from the paper is that prior to the addition of residual inputs and the normalization. ![Scaled Dot Product Attention and Multi-Head Attention](../assets/multi-head-attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    '''The Multi-Head Attention component comes from the \n",
    "    [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper. \n",
    "    For the purpose of simplicity we combine the two parts of the Multi-Headed Attention \n",
    "    into one module'''\n",
    "    def __init__(self, \n",
    "                 ni: int, # The input dimension \n",
    "                 nh: int): # The number of attention heads\n",
    "        ''''''\n",
    "        super().__init__()\n",
    "        self.nh = nh\n",
    "        self.scale = math.sqrt(ni / nh)\n",
    "        self.kqv = nn.Linear(ni, ni*3)\n",
    "        self.proj = nn.Linear(ni, ni)\n",
    "        \n",
    "    def forward(self, inp: tensor):\n",
    "        x = self.kqv(inp)\n",
    "        x = rearrange(x, 'n s (h d) -> (n h) s d', h=self.nh)\n",
    "        \n",
    "        Q, K, V = torch.chunk(x, 3, dim=-1)\n",
    "        x = F.softmax(Q @ K.transpose(1,2) / self.scale, dim=-1) @ V\n",
    "    \n",
    "        x = rearrange(x, '(n h) s d -> n s (h d)', h=self.nh)\n",
    "        x = self.proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = MultiHeadAttention(n_hidden, n_hidden)\n",
    "ho = attention(inp)\n",
    "ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(ho.shape, out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ConvNetwork(nn.Module):\n",
    "    '''The Convolution network consists of two Conv1D layers with the \n",
    "    intermediate dimension being named the filter size.'''\n",
    "    def __init__(self, \n",
    "                 ni: int, # Input dimension \n",
    "                 fs: int, # Filter size for intermediate dimension\n",
    "                 ks: list[int]): # A two element array of kernal sizes\n",
    "        ''''''\n",
    "        super().__init__()\n",
    "        assert len(ks) == 2\n",
    "        padding = list(map(lambda x: (x - 1) // 2, ks))\n",
    "        self.layers = nn.ModuleList([nn.Conv1d(ni, fs, ks[0], padding=padding[0]),\n",
    "                                     nn.Conv1d(fs, ni, ks[1], padding=padding[1])])\n",
    "        \n",
    "    def forward(self, inp: tensor):\n",
    "        x = inp.transpose(1,2)\n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))\n",
    "        return x.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net = ConvNetwork(n_hidden, filter_sz, [9, 1])\n",
    "ho = conv_net(ho)\n",
    "ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(ho.shape, out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FeedForwardTransformer(nn.Module):\n",
    "    ''''''\n",
    "    def __init__(self, \n",
    "                 ni: int, # Input dimension\n",
    "                 nh: int, # Number of attention heads\n",
    "                 fs: int, # Filter size for intermediate dimension\n",
    "                 ks: list[int], # A two element list of kernal sizes\n",
    "                 p: list[float]): # A two element list of dropout probabilities\n",
    "        '''This module consists of a MultiHeadAttention, and ConvNetwork layer with \n",
    "        dropout, residuals, and layer normalization being applied after each layer'''\n",
    "        super().__init__()\n",
    "        assert len(ks) == 2 and len(p) == 2\n",
    "        self.layers = nn.ModuleList([MultiHeadAttention(ni, nh), ConvNetwork(ni, fs, ks)])\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(ni) for _ in range(2)])\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(p[i]) for i in range(2)])\n",
    "        \n",
    "    def forward(self, inp: tensor):\n",
    "        res = inp\n",
    "        modules = zip(self.layers, self.norms, self.dropouts)\n",
    "        for layer, norm, dropout in modules:\n",
    "            x = layer(res)\n",
    "            x = norm(dropout(x) + res)\n",
    "            res = x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FFTConfig:\n",
    "    '''To allow for easily configurable FFT modules we decided to create a FFTConfig\n",
    "    to allow for more readable, and customizable code when creating FFT'''\n",
    "    def __init__(self, \n",
    "                 ni: int, # The input size\n",
    "                 nh: int, # The number of attention heads\n",
    "                 fs: int, # Filter size for intermediate dimension\n",
    "                 ks: list[int], # A two element list of kernal sizes\n",
    "                 p: list[float]): # A two element list of dropout probabilities\n",
    "        self.ni, self.nh, self.fs, self.ks, self.p = ni, nh, fs, ks, p\n",
    "    \n",
    "    def build(self):\n",
    "        return FeedForwardTransformer(self.ni, self.nh, self.fs, self.ks, self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft = FeedForwardTransformer(n_hidden, n_heads, filter_sz, \n",
    "                             ks=[9, 1], p=[0.1, 0.1])\n",
    "ho = fft(inp)\n",
    "ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(ho.shape, out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## duration predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DurationPredictor(nn.Module):\n",
    "    '''This module predicts the logarithmic duration length for each phoneme \n",
    "    based on the phoneme hidden features. It consists of 2-layer 1D convolutional network \n",
    "    with ReLU activation, each followed by the layer normalization and the dropout layer, \n",
    "    and an extra linear layer to output a scalar.'''\n",
    "    def __init__(self, \n",
    "                 ni: int, # Input dimension\n",
    "                 fs: int, # Filter size for intermediate dimension\n",
    "                 ks: list[int], # A two element list of kernal sizes\n",
    "                 p: list[float]): # A two element list of dropout probabilities\n",
    "        ''''''\n",
    "        super().__init__()\n",
    "        assert len(ks) == 2 and len(p) == 2\n",
    "        \n",
    "        padding = list(map(lambda x: (x - 1) // 2, ks))\n",
    "        self.layers = nn.ModuleList([nn.Conv1d(ni, fs, ks[0], padding=padding[0]),\n",
    "                                     nn.Conv1d(fs, ni, ks[1], padding=padding[1])])\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(sz) for sz in [fs, ni]])\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(p[i]) for i in range(2)])\n",
    "        self.linear = nn.Linear(ni, 1)\n",
    "    \n",
    "    def forward(self, hi: tensor):\n",
    "        x = hi\n",
    "        modules = zip(self.layers, self.norms, self.dropouts)\n",
    "        for layer, norm, dropout in modules:\n",
    "            x = layer(x.transpose(1, 2))\n",
    "            x = dropout(F.relu(x))\n",
    "            x = norm(x.transpose(1,2))\n",
    "        x = self.linear(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DPConfig:\n",
    "    '''To allow for easily configurable Deration Predictor modules we \n",
    "    decided to create a DPConfig to allow for more readable, \n",
    "    and customizable code when creating Duration Predcitor modules'''\n",
    "    def __init__(self, \n",
    "                 ni: int, # Input dimension\n",
    "                 fs: int, # Filter size for intermediate dimension\n",
    "                 ks: list[int], # A two element list of kernal sizes\n",
    "                 p: list[float]): # A two element list of dropout probabilities\n",
    "        self.ni, self.fs, self.ks, self.p = ni, fs, ks, p\n",
    "    \n",
    "    def build(self):\n",
    "        return DurationPredictor(self.ni, self.fs, self.ks, self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_pred = DurationPredictor(n_hidden, filter_sz, \n",
    "                                  [3,3], [0.1,0.1])\n",
    "log_durations = duration_pred(ho)\n",
    "log_durations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(log_durations.shape, [bs, seq_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## length regulator\n",
    "> This module upsamples the phoneme hidden feature to the size of the melspectrogram based on the phoneme durations provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def length_regulator(hi: tensor, # The hidden phoneme features\n",
    "                     durations: tensor, # The phoneme durations to upsample to\n",
    "                     upsample_ratio: float, # The multiplier ratio of upsampling rate\n",
    "                     device: torch.device = None): # Device you want to use\n",
    "    assert len(durations.sum(dim=1).unique()) == 1\n",
    "    durations = (upsample_ratio * durations).to(torch.int)\n",
    "    \n",
    "    (bs, _, nh), sl = inp.shape, durations[0].sum().item()\n",
    "    \n",
    "    ho = torch.zeros((bs, sl, nh), device=device)\n",
    "    for i in range(bs):\n",
    "        ho[i] = hi[i].repeat_interleave(durations[i], dim=0)\n",
    "    return ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 36, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations = tensor([[2]*seq_len for i in range(bs)])\n",
    "ho = length_regulator(ho, durations, 1.)\n",
    "ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(ho.shape, [bs, durations[0].sum(), n_hidden])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fastspeech\n",
    "> This is module will contain the full architecture for FastSpeech. it will consists of the feed-forward Transformer block, the length regulator, and the duration predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FastSpeech(nn.Module):\n",
    "    ''''''\n",
    "    def __init__(self, \n",
    "                 ne: int, # Number of embeddings (vocab size) \n",
    "                 ni: int, # The number of hidden dimension\n",
    "                 no: int, # The number of outputs bins (mel bins)\n",
    "                 ec: FFTConfig, # Encoder config \n",
    "                 enb: int, # The number of FFT in encoder\n",
    "                 dc: FFTConfig, # Decoder config\n",
    "                 dnb: int, #The number of FFT in decoder\n",
    "                 dpc: DPConfig, # Duration Predictor config\n",
    "                 device=None):\n",
    "        ''''''\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.embedding = nn.Embedding(ne, ni)\n",
    "        self.encoder = nn.Sequential(*[ec.build() for _ in range(enb)])\n",
    "        self.decoder = nn.Sequential(*[dc.build() for _ in range(dnb)])\n",
    "        self.duration_predictor = dpc.build()\n",
    "        self.linear = nn.Linear(ni, no)\n",
    "        \n",
    "    def forward(self, inp: tensor, # The input phonemes in vectorized form\n",
    "                durations: tensor = None, # The phoneme durations, used for training\n",
    "                upsample_ratio: float = 1.): # Upsampling ratio (adjust speed of speech)\n",
    "        x = self.embedding(inp)\n",
    "        x = x +  get_positional_embeddings(*x.shape[-2:], device=self.device)\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        log_durations = self.duration_predictor(x.detach())\n",
    "        if durations == None or not self.training:\n",
    "            durations = log_durations.exp()\n",
    "        x = length_regulator(x, durations, upsample_ratio, device=self.device)\n",
    "        \n",
    "        x = x +  get_positional_embeddings(*x.shape[-2:], device=self.device)\n",
    "        x = self.decoder(x)\n",
    "        x = self.linear(x).transpose(1,2)\n",
    "        \n",
    "        return (x, log_durations) if self.training else x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 80, 36])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_config = FFTConfig(n_hidden, n_heads, 64, [9,1], [0.1,0.1])\n",
    "decoder_config = FFTConfig(n_hidden, n_heads, 64, [3,3], [0.1,0.1])\n",
    "dp_config = DPConfig(n_hidden, 48, [3,3], [0.1, 0.1])\n",
    "\n",
    "model = FastSpeech(vocab_sz, n_hidden, 80, encoder_config, 4,\n",
    "                   decoder_config, 6, dp_config)\n",
    "with torch.no_grad(): mel, _ = model(sample_batch, durations)\n",
    "mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_mel(mel[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
