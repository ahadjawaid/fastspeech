{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modules\n",
    "\n",
    "> This package contains the modules that make up the [FastSpeech](https://arxiv.org/abs/1905.09263) architecture\n",
    "![](../assets/fastspeech-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "import math\n",
    "from einops import rearrange\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def get_shape(*args: tensor): return tuple(map(lambda x: x.shape, [*args]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "vocab_sz = 50\n",
    "n_hidden = 48\n",
    "filter_sz = 64\n",
    "n_heads = 2\n",
    "bs = 16\n",
    "seq_len = 18\n",
    "out_shape = [bs, seq_len, n_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "sample_batch = torch.randint(vocab_sz, (bs, seq_len))\n",
    "sample_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phoneme Embedding\n",
    "> The first module of the fastspeech architecture is the input embeddings where they embed the input phonemes in to the models hidden dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(vocab_sz, n_hidden)\n",
    "samples_embedded = embedding(sample_batch)\n",
    "samples_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(out_shape, samples_embedded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Embedding\n",
    "> After the embedding layer in the fastspeech model it inputs positional embedding to allow the model to have information on the positons of inputs. The positional embedding used in the [FastSpeech](https://arxiv.org/abs/1905.09263) paper is the function described in the [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_positional_embeddings(seq_len, # The length of the sequence\n",
    "                              d_model, # The hidden dimension of the model\n",
    "                              device: torch.device =None): # Device you want to use\n",
    "    pos = torch.arange(d_model, device=device)[None, :]\n",
    "    i = torch.arange(seq_len, device=device)[:, None]\n",
    "    angle = pos / torch.pow(10000, 2 * i / d_model)\n",
    "    pos_emb = torch.zeros(angle.shape, device=device)\n",
    "    pos_emb[0::2,:], pos_emb[1::2,:] = angle[0::2,:].sin(), angle[1::2,:].cos()\n",
    "    return pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb = get_positional_embeddings(seq_len, n_hidden)\n",
    "pos_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(pos_emb.shape, [seq_len, n_hidden])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = samples_embedded + pos_emb\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(inp.shape, out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward Transformer\n",
    "> This component of the model is the engine of the model. It is what will be used to make up the phoneme encoder and mel spectrogram decoder. It consists of a Multi-Head Attention block and a Conv Network. An additional note from the paper is that prior to the addition of residual inputs and the normalization. ![Scaled Dot Product Attention and Multi-Head Attention](../assets/multi-head-attention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    '''The Multi-Head Attention component comes from the \n",
    "    [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper. \n",
    "    For the purpose of simplicity we combine the two parts of the Multi-Headed Attention \n",
    "    into one module'''\n",
    "    def __init__(self, \n",
    "                 ni: int, # The input dimension \n",
    "                 nh: int): # The number of attention heads\n",
    "        ''''''\n",
    "        super().__init__()\n",
    "        self.nh = nh\n",
    "        self.scale = math.sqrt(ni / nh)\n",
    "        self.kqv = nn.Linear(ni, ni*3)\n",
    "        self.proj = nn.Linear(ni, ni)\n",
    "        \n",
    "    def forward(self, inp: tensor):\n",
    "        x = self.kqv(inp)\n",
    "        x = rearrange(x, 'n s (h d) -> (n h) s d', h=self.nh)\n",
    "        \n",
    "        Q, K, V = torch.chunk(x, 3, dim=-1)\n",
    "        x = F.softmax(Q @ K.transpose(1,2) / self.scale, dim=-1) @ V\n",
    "    \n",
    "        x = rearrange(x, '(n h) s d -> n s (h d)', h=self.nh)\n",
    "        x = self.proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = MultiHeadAttention(n_hidden, n_hidden)\n",
    "ho = attention(inp)\n",
    "ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(ho.shape, out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ConvNetwork(nn.Module):\n",
    "    '''The Convolution network consists of two Conv1D layers with the \n",
    "    intermediate dimension being named the filter size.'''\n",
    "    def __init__(self, \n",
    "                 ni: int, # Input dimension \n",
    "                 fs: int, # Filter size for intermediate dimension\n",
    "                 ks: list[int]): # A two element array of kernal sizes\n",
    "        ''''''\n",
    "        super().__init__()\n",
    "        assert len(ks) == 2\n",
    "        padding = list(map(lambda x: (x - 1) // 2, ks))\n",
    "        self.layers = nn.ModuleList([nn.Conv1d(ni, fs, ks[0], padding=padding[0]),\n",
    "                                     nn.Conv1d(fs, ni, ks[1], padding=padding[1])])\n",
    "        \n",
    "    def forward(self, inp: tensor):\n",
    "        x = inp.transpose(1,2)\n",
    "        for layer in self.layers:\n",
    "            x = F.relu(layer(x))\n",
    "        return x.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_net = ConvNetwork(n_hidden, filter_sz, [9, 1])\n",
    "ho = conv_net(ho)\n",
    "ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(ho.shape, out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FeedForwardTransformer(nn.Module):\n",
    "    ''''''\n",
    "    def __init__(self, \n",
    "                 ni: int, # Input dimension\n",
    "                 nh: int, # Number of attention heads\n",
    "                 fs: int, # Filter size for intermediate dimension\n",
    "                 ks: list[int], # A two element list of kernal sizes\n",
    "                 p: list[float]): # A two element list of dropout probabilities\n",
    "        '''This module consists of a MultiHeadAttention, and ConvNetwork layer with \n",
    "        dropout, residuals, and layer normalization being applied after each layer'''\n",
    "        super().__init__()\n",
    "        assert len(ks) == 2 and len(p) == 2\n",
    "        self.layers = nn.ModuleList([MultiHeadAttention(ni, nh), ConvNetwork(ni, fs, ks)])\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(ni) for _ in range(2)])\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(p[i]) for i in range(2)])\n",
    "        \n",
    "    def forward(self, inp: tensor):\n",
    "        res = inp\n",
    "        modules = zip(self.layers, self.norms, self.dropouts)\n",
    "        for layer, norm, dropout in modules:\n",
    "            x = layer(res)\n",
    "            x = norm(dropout(x) + res)\n",
    "            res = x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FFTConfig:\n",
    "    '''To allow for easily configurable FFT modules we decided to create a FFTConfig\n",
    "    to allow for more readable, and customizable code when creating FFT'''\n",
    "    def __init__(self, \n",
    "                 ni: int, # The input size\n",
    "                 nh: int, # The number of attention heads\n",
    "                 fs: int, # Filter size for intermediate dimension\n",
    "                 ks: list[int], # A two element list of kernal sizes\n",
    "                 p: list[float]): # A two element list of dropout probabilities\n",
    "        self.ni, self.nh, self.fs, self.ks, self.p = ni, nh, fs, ks, p\n",
    "    \n",
    "    def build(self):\n",
    "        return FeedForwardTransformer(self.ni, self.nh, self.fs, self.ks, self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fft = FeedForwardTransformer(n_hidden, n_heads, filter_sz, \n",
    "                             ks=[9, 1], p=[0.1, 0.1])\n",
    "ho = fft(inp)\n",
    "ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(ho.shape, out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DurationPredictor(nn.Module):\n",
    "    '''This module predicts the logarithmic duration length for each phoneme \n",
    "    based on the phoneme hidden features. It consists of 2-layer 1D convolutional network \n",
    "    with ReLU activation, each followed by the layer normalization and the dropout layer, \n",
    "    and an extra linear layer to output a scalar.'''\n",
    "    def __init__(self, \n",
    "                 ni: int, # Input dimension\n",
    "                 fs: int, # Filter size for intermediate dimension\n",
    "                 ks: list[int], # A two element list of kernal sizes\n",
    "                 p: list[float]): # A two element list of dropout probabilities\n",
    "        ''''''\n",
    "        super().__init__()\n",
    "        assert len(ks) == 2 and len(p) == 2\n",
    "        \n",
    "        padding = list(map(lambda x: (x - 1) // 2, ks))\n",
    "        self.layers = nn.ModuleList([nn.Conv1d(ni, fs, ks[0], padding=padding[0]),\n",
    "                                     nn.Conv1d(fs, ni, ks[1], padding=padding[1])])\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(sz) for sz in [fs, ni]])\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(p[i]) for i in range(2)])\n",
    "        self.linear = nn.Linear(ni, 1)\n",
    "    \n",
    "    def forward(self, hi: tensor):\n",
    "        x = hi\n",
    "        modules = zip(self.layers, self.norms, self.dropouts)\n",
    "        for layer, norm, dropout in modules:\n",
    "            x = layer(x.transpose(1, 2))\n",
    "            x = dropout(F.relu(x))\n",
    "            x = norm(x.transpose(1,2))\n",
    "        x = self.linear(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DPConfig:\n",
    "    '''To allow for easily configurable Deration Predictor modules we \n",
    "    decided to create a DPConfig to allow for more readable, \n",
    "    and customizable code when creating Duration Predcitor modules'''\n",
    "    def __init__(self, \n",
    "                 ni: int, # Input dimension\n",
    "                 fs: int, # Filter size for intermediate dimension\n",
    "                 ks: list[int], # A two element list of kernal sizes\n",
    "                 p: list[float]): # A two element list of dropout probabilities\n",
    "        self.ni, self.fs, self.ks, self.p = ni, fs, ks, p\n",
    "    \n",
    "    def build(self):\n",
    "        return DurationPredictor(self.ni, self.fs, self.ks, self.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 18])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_pred = DurationPredictor(n_hidden, filter_sz, \n",
    "                                  [3,3], [0.1,0.1])\n",
    "log_durations = duration_pred(ho)\n",
    "log_durations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(log_durations.shape, [bs, seq_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length Regulator\n",
    "> This module upsamples the phoneme hidden feature to the size of the melspectrogram based on the phoneme durations provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def length_regulator(hi: tensor, # The hidden phoneme features\n",
    "                     durations: tensor, # The phoneme durations to upsample to\n",
    "                     upsample_ratio: float, # The multiplier ratio of upsampling rate\n",
    "                     device: torch.device = None): # Device you want to use\n",
    "    assert len(durations.sum(dim=1).unique()) == 1\n",
    "    durations = (upsample_ratio * durations).to(torch.int)\n",
    "    \n",
    "    (bs, _, nh), sl = inp.shape, durations[0].sum().item()\n",
    "    \n",
    "    ho = torch.zeros((bs, sl, nh), device=device)\n",
    "    for i in range(bs):\n",
    "        ho[i] = hi[i].repeat_interleave(durations[i], dim=0)\n",
    "    return ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 36, 48])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations = tensor([[2]*seq_len for i in range(bs)])\n",
    "ho = length_regulator(ho, durations, 1.)\n",
    "ho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_eq(ho.shape, [bs, durations[0].sum(), n_hidden])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastspeech\n",
    "> This is module will contain the full architecture for FastSpeech. it will consists of the feed-forward Transformer block, the length regulator, and the duration predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FastSpeech(nn.Module):\n",
    "    ''''''\n",
    "    def __init__(self, \n",
    "                 ne: int, # Number of embeddings (vocab size) \n",
    "                 ni: int, # The number of hidden dimension\n",
    "                 no: int, # The number of outputs bins (mel bins)\n",
    "                 ec: FFTConfig, # Encoder config \n",
    "                 enb: int, # The number of FFT in encoder\n",
    "                 dc: FFTConfig, # Decoder config\n",
    "                 dnb: int, #The number of FFT in decoder\n",
    "                 dpc: DPConfig, # Duration Predictor config\n",
    "                 device=None):\n",
    "        ''''''\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.embedding = nn.Embedding(ne, ni)\n",
    "        self.encoder = nn.Sequential(*[ec.build() for _ in range(enb)])\n",
    "        self.decoder = nn.Sequential(*[dc.build() for _ in range(dnb)])\n",
    "        self.duration_predictor = dpc.build()\n",
    "        self.linear = nn.Linear(ni, no)\n",
    "        \n",
    "    def forward(self, inp: tensor, # The input phonemes in vectorized form\n",
    "                durations: tensor = None, # The phoneme durations, used for training\n",
    "                upsample_ratio: float = 1.): # Upsampling ratio (adjust speed of speech)\n",
    "        x = self.embedding(inp)\n",
    "        x = x +  get_positional_embeddings(*x.shape[-2:], device=self.device)\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        log_durations = self.duration_predictor(x.detach())\n",
    "        if durations == None or not self.training:\n",
    "            durations = log_durations.exp()\n",
    "        x = length_regulator(x, durations, upsample_ratio, device=self.device)\n",
    "        \n",
    "        x = x +  get_positional_embeddings(*x.shape[-2:], device=self.device)\n",
    "        x = self.decoder(x)\n",
    "        x = self.linear(x).transpose(1,2)\n",
    "        \n",
    "        return (x, log_durations) if self.training else x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 80, 36])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_config = FFTConfig(n_hidden, n_heads, 64, [9,1], [0.1,0.1])\n",
    "decoder_config = FFTConfig(n_hidden, n_heads, 64, [3,3], [0.1,0.1])\n",
    "dp_config = DPConfig(n_hidden, 48, [3,3], [0.1, 0.1])\n",
    "\n",
    "model = FastSpeech(vocab_sz, n_hidden, 80, encoder_config, 4,\n",
    "                   decoder_config, 6, dp_config)\n",
    "with torch.no_grad(): mel, _ = model(sample_batch, durations)\n",
    "mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(librosa.power_to_db(mel[0]), origin='lower');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
