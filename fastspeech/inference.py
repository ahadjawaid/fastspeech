# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/07-inference.ipynb.

# %% auto 0
__all__ = ['g2p', 'load_model_inference', 'filter_non_alpha_chars', 'preprocess_text', 'inference', 'bayesian_inference']

# %% ../nbs/07-inference.ipynb 3
from .modules import FastSpeech
from .training import load_checkpoint
from .visualize import *
from .data import Vocab
import torch
import librosa
from .preprocess import reduce_noise
from g2p_en import G2p
import re

# %% ../nbs/07-inference.ipynb 7
def load_model_inference(Model, checkpoint_path, training=False):
    state_dict, config, norm = load_checkpoint(checkpoint_path, 'cpu')
    model = Model(config["model"])
    model.load_state_dict(state_dict['model'])
    model = model.train(mode=training)
    return model, norm

# %% ../nbs/07-inference.ipynb 10
def filter_non_alpha_chars(input_str):
    return re.sub(r'[^A-Za-z ]', '', input_str)

# %% ../nbs/07-inference.ipynb 12
g2p = G2p()

# %% ../nbs/07-inference.ipynb 13
def preprocess_text(text, vocab_path):
    vocab = Vocab(vocab_path)
    text = filter_non_alpha_chars(text)
    phones = g2p(text)
    phones = list(filter(lambda x: x != ' ', phones))
    vec = torch.tensor(list(map(vocab.tok2idx.__getitem__, phones))).unsqueeze(0)
    return vec

# %% ../nbs/07-inference.ipynb 15
def inference(vec, model, upsample_ratio=1.):
    model = model.train(mode=False)
    with torch.no_grad(): mel = model(vec, upsample_ratio=upsample_ratio)
    return mel.squeeze()

# %% ../nbs/07-inference.ipynb 17
def bayesian_inference(vec, model, samples=10, upsample_ratio=1.):
    '''Does ensemabling based on averaging between different 
    prediction with dropout left on to add varience between each predicition'''
    model = model.train(mode=True)
    
    durr_preds = torch.stack([model(vec)[1] for _ in range(samples)])
    durr_mean = durr_preds.mean(dim=0)
    durr_stacked = torch.stack([durr_mean.squeeze() for d in durr_preds])
    vec_stacked = torch.stack([vec.squeeze() for _ in range(samples)])

    with torch.no_grad(): mels = model(vec_stacked, durr_stacked, upsample_ratio)[0]
    averaged_mel = mels.mean(dim=0)
    return averaged_mel
