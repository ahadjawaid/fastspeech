# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_preprocess.ipynb.

# %% auto 0
__all__ = ['map_tensors', 'Vocab', 'phones_list_to_num', 'pad_phones', 'trim_audio', 'pad_mels', 'round_and_align_durations',
           'pad_duration', 'flatten_and_concat', 'ZScoreNormalization', 'MinMaxNormalization']

# %% ../nbs/04_preprocess.ipynb 3
from pathlib import Path
import librosa
from numpy import array
import torch
import numpy as np
from torch.nn.utils.rnn import pad_sequence
from fastcore.foundation import L
from torch import tensor

# %% ../nbs/04_preprocess.ipynb 7
def map_tensors(inp: list[list]):
    return list(map(tensor, inp))

# %% ../nbs/04_preprocess.ipynb 10
class Vocab:
    '''This is a vocab object to used to load in a vocabulary, vectorize phonemes, and decode embeddings'''
    def __init__(self, 
                 vocab_path: str, # The path to vocabulary file containing all the words in the vocabulary
                 specials: list =[]): # The special tokens not in the vocabulary file
        pad_token = "<pad>"
        self.vocab = self._load_vocab(vocab_path) + [pad_token] + specials
        self.tok2idx = {tok: i for i, tok in enumerate(self.vocab)}
        self.pad_num = self.tok2idx[pad_token]
    
    def __getitem__(self, val): # The token string or the vectorized integer
        val_type = type(val)
        if val_type == int and val < len(self.vocab): 
            return self.vocab[val]
        elif val_type == str:
            return self.tok2idx[val]
        else:
            raise Exception(f"Used the wrong type: {val_type}")
        
    def __len__(self):
        return len(self.vocab)
        
    def _load_vocab(self, vocab_path: str): # The path to the phoneme vocab list
        lines = Path(vocab_path).open().readlines()
        return list(map(lambda x: x.strip(), lines))

# %% ../nbs/04_preprocess.ipynb 12
def phones_list_to_num(phones: list[list[int]], vocab: Vocab):
    nums = L(phones).map(lambda x: L(x).map(vocab.__getitem__))
    return nums

# %% ../nbs/04_preprocess.ipynb 14
def pad_phones(phones: list[tensor], pad_num: int):
    return pad_sequence(phones, batch_first=True, padding_value=pad_num)

# %% ../nbs/04_preprocess.ipynb 18
def trim_audio(inp: array, # Input audio array
               top_db: int, # The threshold (in decibels) below reference to consider as silence
               n_fft: int, # The number of samples per analysis frame
               hl: int): # The number of samples between analysis frames
    audio, _  = librosa.effects.trim(y=inp, top_db=top_db, frame_length=n_fft, hop_length=hl)
    return audio

# %% ../nbs/04_preprocess.ipynb 23
def pad_mels(mels: list[tensor]):
    return pad_sequence(L(mels).map(lambda x: x.T), batch_first=True).transpose(1, 2)

# %% ../nbs/04_preprocess.ipynb 27
def round_and_align_durations(duration: tensor, mel_len: int):
    '''Rounds duration such that durations add up to the mel length and if 
    they don\'t add up it adds to each phoneme based on difference between 
    rounded and duration'''
    rounded_duration = duration.round()
    total_duration = rounded_duration.sum().int().item()
    
    if total_duration != mel_len:
        unit = -1 if total_duration > mel_len else 1
        
        descending = True if unit == 1 else False
        sorted_idxs = torch.argsort((rounded_duration-duration), descending=descending)
        n = len(sorted_idxs)
        
        difference = int(abs(total_duration - mel_len))
        for i in range(difference):
            idx = sorted_idxs[i % n]
            rounded_duration[idx] += unit
            
    return rounded_duration

# %% ../nbs/04_preprocess.ipynb 30
def pad_duration(duration):
    return pad_sequence(duration, batch_first=True)

# %% ../nbs/04_preprocess.ipynb 33
def flatten_and_concat(arrays: list[array]):
    concatenated_arrays = np.concatenate([a.flatten() for a in arrays])
    return concatenated_arrays

# %% ../nbs/04_preprocess.ipynb 35
class ZScoreNormalization:
    def __init__(self, mean: float, std: float):
        '''Creates a normalization object that allows for normalization and 
        denormalization'''
        self.mean, self.std = mean, std
        
    def normalize(self, inp: tensor):
        return (inp - mean) / std
    
    def denormalize(self, inp: tensor):
        return inp * std + mean

# %% ../nbs/04_preprocess.ipynb 37
class MinMaxNormalization:
    def __init__(self, max_val: float, min_val: float):
        '''Creates a normalization object that allows for normalization and 
        denormalization'''
        self.max_val, self.min_val = max_val, min_val
    
    def normalize(self, inp):
        return (inp - self.min_val) / (self.max_val - self.min_val)
    
    def denormalize(self, inp):
        return inp * (self.max_val - self.min_val) + self.min_val
