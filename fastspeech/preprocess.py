# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_preprocess.ipynb.

# %% auto 0
__all__ = ['map_tensors', 'argmax_all', 'pad_max_seq', 'Vocab', 'phones_list_to_num', 'pad_phones', 'trim_audio', 'reduce_noise',
           'pad_mels', 'extract_pitch', 'extract_energy', 'round_and_align_durations', 'pad_duration',
           'flatten_and_concat', 'ZScoreNormalization', 'MinMaxNormalization', 'NoNorm', 'torch_digitize',
           'linear_quantization', 'logarithmic_quantization', 'transform_inp']

# %% ../nbs/04_preprocess.ipynb 3
from pathlib import Path
import librosa
from numpy import array
import torch
import pyworld as pw
import numpy as np
from torch.nn.utils.rnn import pad_sequence
import noisereduce as nr
from fastcore.foundation import L
from torch import tensor

# %% ../nbs/04_preprocess.ipynb 8
def map_tensors(inp: list[list]):
    return list(map(tensor, inp))

# %% ../nbs/04_preprocess.ipynb 10
def argmax_all(tens):
    max_val = 0
    max_idxs = []
    for i in range(len(tens)):
        val = tens[i].item()
        if val > max_val:
            max_val = val
            max_idxs = [i]
        elif val == max_val:
            max_idxs.append(i)
    return max_idxs

# %% ../nbs/04_preprocess.ipynb 12
def pad_max_seq(seq: list[tensor], pad_val=0, pad_len=1):
    seq_pad = L(seq[:])
    max_idxs = argmax_all(tensor(seq_pad.map(len)))
    for idx in max_idxs:
        seq_pad[idx] = torch.cat((seq_pad[idx], torch.tensor([pad_val]*pad_len)))
    return seq_pad

# %% ../nbs/04_preprocess.ipynb 15
class Vocab:
    '''This is a vocab object to used to load in a vocabulary, vectorize phonemes, and decode embeddings'''
    def __init__(self, 
                 vocab_path: str, # The path to vocabulary file containing all the words in the vocabulary
                 specials: list =[]): # The special tokens not in the vocabulary file
        pad_token = "<pad>"
        self.vocab = self._load_vocab(vocab_path) + [pad_token] + specials
        self.tok2idx = {tok: i for i, tok in enumerate(self.vocab)}
        self.pad_num = self.tok2idx[pad_token]
    
    def __getitem__(self, val): # The token string or the vectorized integer
        val_type = type(val)
        if val_type == int and val < len(self.vocab): 
            return self.vocab[val]
        elif val_type == str:
            return self.tok2idx[val]
        else:
            raise Exception(f"Used the wrong type: {val_type}")
        
    def __len__(self):
        return len(self.vocab)
        
    def _load_vocab(self, vocab_path: str): # The path to the phoneme vocab list
        lines = Path(vocab_path).open().readlines()
        return list(map(lambda x: x.strip(), lines))

# %% ../nbs/04_preprocess.ipynb 17
def phones_list_to_num(phones: list[list[int]], vocab: Vocab):
    nums = L(phones).map(lambda x: L(x).map(vocab.__getitem__))
    return nums

# %% ../nbs/04_preprocess.ipynb 19
def pad_phones(phones: list[tensor], pad_num: int):
    return pad_sequence(phones, batch_first=True, padding_value=pad_num)

# %% ../nbs/04_preprocess.ipynb 23
def trim_audio(inp: array, # Input audio array
               top_db: int, # The threshold (in decibels) below reference to consider as silence
               n_fft: int, # The number of samples per analysis frame
               hl: int): # The number of samples between analysis frames
    audio, _  = librosa.effects.trim(y=inp, top_db=top_db, frame_length=n_fft, hop_length=hl)
    return audio

# %% ../nbs/04_preprocess.ipynb 28
def reduce_noise(wav, sr, *args, **kwargs):
    return nr.reduce_noise(wav, sr=sr, *args, **kwargs)

# %% ../nbs/04_preprocess.ipynb 31
def pad_mels(mels: list[tensor], norm_val=0):
    return pad_sequence(L(mels).map(lambda x: x.T), batch_first=True, 
                        padding_value=norm_val).transpose(1, 2)

# %% ../nbs/04_preprocess.ipynb 33
def extract_pitch(wav, sr=22050, hop_length=256):
    f0, t = pw.dio(wav.astype(np.float64), fs=sr, 
               frame_period=hop_length/sr * 1000)
    pitch = pw.stonemask(wav.astype(np.float64), f0, t, fs=sr)
    return pitch.astype(np.float32)

# %% ../nbs/04_preprocess.ipynb 35
def extract_energy(wav, n_fft=1024, hop_length=256):
    stft = librosa.stft(y=wav, n_fft=n_fft, hop_length=hop_length)
    amplitude = np.abs(stft)
    energy = np.linalg.norm(amplitude, axis=0)
    return energy

# %% ../nbs/04_preprocess.ipynb 39
def round_and_align_durations(duration: tensor, mel_len: int):
    '''Rounds duration such that durations add up to the mel length and if 
    they don\'t add up it adds to each phoneme based on difference between 
    rounded and duration'''
    rounded_duration = duration.round()
    total_duration = rounded_duration.sum().int().item()
    
    if total_duration != mel_len:
        unit = -1 if total_duration > mel_len else 1
        
        descending = True if unit == 1 else False
        sorted_idxs = torch.argsort((rounded_duration-duration), descending=descending)
        n = len(sorted_idxs)
        
        difference = int(abs(total_duration - mel_len))
        for i in range(difference):
            idx = sorted_idxs[i % n]
            rounded_duration[idx] += unit
            
    return rounded_duration

# %% ../nbs/04_preprocess.ipynb 42
def pad_duration(duration: list[tensor], mel_len: int):
    padded_duration = pad_sequence(duration, batch_first=True)
    padded_duration_amount = [mel_len - dur.sum().item() for dur in duration]
    padded_duration[:, -1] = tensor(padded_duration_amount)
    return padded_duration

# %% ../nbs/04_preprocess.ipynb 45
def flatten_and_concat(arrays: list[array]):
    concatenated_arrays = np.concatenate([a.flatten() for a in arrays])
    return concatenated_arrays

# %% ../nbs/04_preprocess.ipynb 47
class ZScoreNormalization:
    def __init__(self, mean: float, std: float, *args, **kwargs):
        '''Creates a normalization object that allows for normalization and 
        denormalization'''
        self.mean, self.std = mean, std
        
    def normalize(self, inp: tensor):
        return (inp - self.mean) / self.std
    
    def denormalize(self, inp: tensor):
        return inp * self.std + self.mean

# %% ../nbs/04_preprocess.ipynb 49
class MinMaxNormalization:
    def __init__(self, max_val: float, min_val: float, *args, **kwargs):
        '''Creates a normalization object that allows for normalization and 
        denormalization'''
        self.max_val, self.min_val = max_val, min_val
    
    def normalize(self, inp):
        return (inp - self.min_val) / (self.max_val - self.min_val)
    
    def denormalize(self, inp):
        return inp * (self.max_val - self.min_val) + self.min_val

# %% ../nbs/04_preprocess.ipynb 51
class NoNorm:
    def __init__(self, *args, **kwargs):
        pass
    def normalize(self, inp):
        return inp
    def denormalize(self, inp):
        return inp

# %% ../nbs/04_preprocess.ipynb 53
def torch_digitize(tensor, bins, device=None):
    indices = torch.zeros_like(tensor, device=device)
    for idx, bin_val in enumerate(bins):
        indices += (tensor >= bin_val).long()
    return indices

# %% ../nbs/04_preprocess.ipynb 54
def linear_quantization(vals, n_bins, min_v=None, max_v=None, device=None):
    if min_v is None: min_v = vals.min().detach().item()
    if max_v is None: max_v = vals.max().detach().item()

    bins = torch.linspace(min_v, max_v, n_bins - 1, device=device)
    
    quantized_vals = torch_digitize(vals, bins, device=device) - 1
    return quantized_vals.to(torch.int)

# %% ../nbs/04_preprocess.ipynb 56
def logarithmic_quantization(vals, n_bins, min_v=None, max_v=None, device=None):
    if min_v is None: min_v = vals.min()
    if max_v is None: max_v = vals.max()
        
    min_v = tensor(max(min_v, 1e-20))
    max_v = tensor(max(max_v, min_v * 1.0001))
    
    min_v = min_v * 0.99993
    import pdb; pdb.set_trace
        
    bins = torch.logspace(torch.log10(min_v), torch.log10(max_v), n_bins, device=device)
    
    quantized_vals = torch_digitize(vals, bins, device=device)
    return quantized_vals.to(torch.int)

# %% ../nbs/04_preprocess.ipynb 59
def transform_inp(inp, transform_list: list):
    x = inp
    for transform in transform_list:
        x = transform(inp)
    return x
